{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBUTEROL SULFATE HFA 90 MCG/ACTUATION AEROSOL INHALER\n",
      "ALBUTEROL SULFATE 2.5 MG/3 ML (0.083 %) NEB SOLUTION\n",
      "HEPARIN SODIUM INJ\n",
      "DOCUSATE SODIUM 100 MG CAPSULE\n",
      "ALBUTEROL SULFATE 2.5 MG/3 ML (0.083 %) NEB SOLUTION\n",
      "DOCUSATE SODIUM CAP\n",
      "HEPARIN (PORCINE) 5,000 UNIT/ML INJECTION\n",
      "SODIUM CHLORIDE 0.9%\n",
      "ZZ IMS TEMPLATE\n",
      "ALBUTEROL 90 MCG/ACTUATION AEROSOL INHALER\n",
      "No significant L1000 drug signatures for ZZ\n",
      "Found significant L1000 drug signatures for ALBUTEROL\n",
      "Found significant L1000 drug signatures for ASPIRIN\n",
      "No significant L1000 drug signatures for OXYCODONE-ACETAMINOPHEN\n",
      "No significant L1000 drug signatures for Fentanyl\n",
      "Found significant L1000 drug signatures for ESOMEPRAZOLE\n",
      "Found significant L1000 drug signatures for PREDNISONE\n",
      "Found significant L1000 drug signatures for IPRATROPIUM\n",
      "Found significant L1000 drug signatures for Propofol\n",
      "Found significant L1000 drug signatures for MONTELUKAST\n",
      "Found significant L1000 drug signatures for DOCUSATE\n"
     ]
    }
   ],
   "source": [
    "## Full backend analysis for the CREEDS and L1000 dataset \n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pandas.compat import StringIO\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import objectpath\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json, requests\n",
    "from pprint import pprint\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from clustergrammer_widget import *\n",
    "def get_geneset(df, indexer):\n",
    "    df_ = df.loc[indexer, :]\n",
    "    return list(df_[df_ == 1].index)\n",
    "\n",
    "\n",
    "## load in the pre-formed datasets from the L1000_Analysis and CREEDS_Analysis files.\n",
    "## THIS TAKES A WHILE TO LOAD, SO ONLY LOAD THIS ONCE AND EARLY\n",
    "\n",
    "# L1000 up and down gene loads for drug signatures\n",
    "L1000_up_genes = pd.read_csv(\"L1000_up_genes.csv\")\n",
    "L1000_down_genes = pd.read_csv(\"L1000_down_genes.csv\")\n",
    "\n",
    "# CREEDS up and down genes for disease signatures\n",
    "with open(\"disease_signatures-v1.0.json\") as f:\n",
    "    CREEDS_data = json.load(f)\n",
    "\n",
    "# generate the up and down gene signatures\n",
    "#CREEDS_up_genes = {\n",
    "#    row['do_id']: row['up_genes']\n",
    "#    for row in CREEDS_data\n",
    "#}\n",
    "#CREEDS_down_genes = {\n",
    "#    row['do_id']: row['down_genes']\n",
    "#    for row in CREEDS_data\n",
    "#}\n",
    "\n",
    "# RETURNS THE do_id, geo_id, and disease name in a dictionary\n",
    "CREEDS_GSE = {\n",
    "    row['id']: [row['geo_id'], row[\"disease_name\"]]\n",
    "    for row in CREEDS_data\n",
    "}\n",
    "\n",
    "# load in the EMR Data (filtered > 200 in R code [Drug_diagnosis_test_code.R])\n",
    "EMR_data = pd.read_csv(\"EMR_greater_200.csv\")\n",
    "## subset EMR data by the DOI and/or DrOI\n",
    "EMR_data_df = pd.DataFrame(EMR_data)\n",
    "#EMR_data\n",
    "EMR_data_df.drop(EMR_data_df.columns[[0]], axis = 1, inplace = True) # remove the unecessary columns\n",
    "#EMR_data_df\n",
    "\n",
    "# implement the search from ICD9-do_id from the manual conversion\n",
    "icd9_to_doid = pd.read_csv(\"ICD9_CREEDS_conversion.csv\")\n",
    "icd9_to_doid = pd.DataFrame(icd9_to_doid) # convert it to a data fram to drop unecessary rows\n",
    "#icd9_to_doid # sanity check\n",
    "icd9_to_doid_final = icd9_to_doid.drop(icd9_to_doid.columns[[0, 6, 7, 8, 9, 10, 11, 12, 13, 14]], axis = 1)\n",
    "#icd9_to_doid_final # sanity check\n",
    "\n",
    "\n",
    "posssible_disease_list = set(icd9_to_doid_final.Disease) \n",
    "#& set(EMR_data_df.Description) # will return {\"Alzheimer's disease\", \"Barrett's esophagus\", 'Dehydration', 'Sepsis'}\n",
    "\n",
    "posssible_disease_list = list(posssible_disease_list) # this will be what the dropdown should display\n",
    "###### GENERATE THE FULL ANALYSIS BETWEEN CREEDS AND L1000 GIVEN A DISEASE OF INTEREST\n",
    "\n",
    "# USER INPUT\n",
    "####\n",
    "DOI = \"asthma\" # disease of interest. CAN TAKE FROM posssible_disease_list FOR NOW\n",
    "####\n",
    "#possible_diseases = EMR_data_df[\"Description\"] #possible diseases from the Sinai EMR\n",
    "\n",
    "### DISEASE --> ICD9 --> DOI\n",
    "# get the ICD9 from the DOI\n",
    "DOI_ICD9 = icd9_to_doid_final[icd9_to_doid_final.Disease.apply(lambda s: bool(re.compile(DOI, re.IGNORECASE).search(s)))]\n",
    "DOI_ICD9_codes = DOI_ICD9.ICD9\n",
    "\n",
    "# get the do_id from the DOI\n",
    "DOI_DOID_codes = DOI_ICD9.DOID\n",
    "\n",
    "# get the do_id from the DOI\n",
    "DOI_CREEDS_codes = DOI_ICD9.CREEDS_drug_id\n",
    "\n",
    "# INPUT SIMILAR CREEDS CODE FROFM THE DRUG_QUERY\n",
    "\n",
    "#DOIDs_up = {\n",
    "#    doid: geneset\n",
    "#    for doid, geneset in CREEDS_up_genes.items()\n",
    "#    if doid in set(DOI_DOID_codes)\n",
    "#}\n",
    "\n",
    "#DOIDs_down = {\n",
    "#    doid: geneset\n",
    "#    for doid, geneset in CREEDS_down_genes.items()\n",
    "#    if doid in set(DOI_DOID_codes)\n",
    "#}\n",
    "    \n",
    "##filter by DOI. Need to convert DOI to ICD9 first.\n",
    "icd9_to_doid_final_search = icd9_to_doid_final[icd9_to_doid_final[\"Disease\"].apply(lambda s: bool(re.compile(DOI, re.IGNORECASE).search(s)))]\n",
    "icd9_to_doid_final_search1 = icd9_to_doid_final_search[\"ICD9\"]\n",
    "\n",
    "## rebuild the wildcard dataframe\n",
    "icd9_wildcard = pd.DataFrame(icd9_to_doid_final_search1, columns=['ICD9'])\n",
    "icd9_wildcard['ICD9_wildcard'] = icd9_wildcard['ICD9'].apply(lambda code: str(code).split('.')[0])\n",
    "icd9_wildcard.head()\n",
    "\n",
    "icd9_to_doid_final['ICD9_wildcard'] = icd9_to_doid_final['ICD9'].apply(lambda code: str(code).split('.')[0])\n",
    "#icd9_to_doid_final.head()\n",
    "ICD9_df_joined = pd.merge(\n",
    "    left=icd9_wildcard, left_on='ICD9_wildcard',\n",
    "    right=icd9_to_doid_final, right_on='ICD9_wildcard',\n",
    "    how='inner',\n",
    "    suffixes=(\n",
    "        '_Manual',\n",
    "        '_right',\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "#ICD9_codes = str(int(ICD9_df_joined[\"ICD9_wildcard\"].unique())) \n",
    "## generate an emr based on the ICD_9 codes extracted; can now extract the drug names as well\n",
    "#emr_sub = EMR_data_df[EMR_data_df['ICD9'].apply(lambda s: bool(re.compile(ICD9_codes, re.IGNORECASE).search(s)))]\n",
    "emr_sub = EMR_data_df[EMR_data_df[\"Description\"].apply(lambda s: bool(re.compile(str(DOI), re.IGNORECASE).search(str(s))))]\n",
    "#emr_sub[0:10]\n",
    "emr_sub.reset_index(drop = True, inplace = True)\n",
    "\n",
    "emr_sub = []\n",
    "for a in ICD9_df_joined.ICD9_wildcard.unique():\n",
    "    emr_sub1 = EMR_data_df[EMR_data_df[\"ICD9\"].apply(lambda s: bool(re.compile(str(a), re.IGNORECASE).search(str(s))))]\n",
    "    emr_sub.append(emr_sub1)\n",
    "emr_sub_df = pd.concat(emr_sub)\n",
    "#### L1000 integration\n",
    "# disease to drug conversion (disease input)\n",
    "top_drugs_from_disease = list(emr_sub_df.Drug_Name[0:10]) #take the top 5 drugs\n",
    "test = pd.DataFrame(L1000_down_genes)\n",
    "#for x in top_drugs_from_disease:\n",
    "#    print(x)\n",
    "#    top_drug_disease_extract = test[test['Unnamed: 0'].apply(lambda s: bool(re.compile(str(x), re.IGNORECASE).search(str(s))))]\n",
    "metadata = pd.read_csv(\"L1000_metadata.csv\")\n",
    "metadata ## same as LINC1000h5.row_metadata_df\n",
    "#metadata\n",
    "for a in top_drugs_from_disease:\n",
    "    print(a)\n",
    "    meta_doi = metadata[metadata[\"pert_desc\"].apply(lambda s: bool(re.compile(str(a), re.IGNORECASE).search(str(s))))]\n",
    "meta_doi\n",
    "meta_doi_ids = meta_doi.rid\n",
    "query = list(meta_doi_ids)\n",
    "#print(query)\n",
    "# disease to drug conversion (disease input)\n",
    "top_drugs_from_disease = list(emr_sub_df.Drug_Name[0:20]) #take the top 5 drugs\n",
    "test = pd.DataFrame(L1000_down_genes)\n",
    "top_drugs_from_disease\n",
    "\n",
    "\n",
    "single_word_drugs = []\n",
    "for i in top_drugs_from_disease:\n",
    "    j = str(i)\n",
    "    splitted = j.split()\n",
    "    first_word = splitted[0]\n",
    "   # print(first_word)\n",
    "    single_word_drugs.append(first_word) \n",
    "#print(single_word_drugs)\n",
    "single_word_drugs = list(set(single_word_drugs))\n",
    "#single_word_drugs\n",
    "\n",
    "# Generate a blacklist process\n",
    "def process_blacklist(s):\n",
    "    import re\n",
    "    blacklist = [\n",
    "        # remove the classifications of the drugs\n",
    "        re.compile(r'INJ', re.IGNORECASE),\n",
    "        re.compile(r'CAP', re.IGNORECASE),\n",
    "        re.compile(r'\\d+', re.IGNORECASE),\n",
    "        \n",
    "        # remove drugs that aren't in the L1000\n",
    "        re.compile(r'SODIUM', re.IGNORECASE),\n",
    "        re.compile(r'HEPATITIS', re.IGNORECASE),\n",
    "        re.compile(r'HEPARIN', re.IGNORECASE),\n",
    "        re.compile(r'CALCIUM', re.IGNORECASE),\n",
    "        \n",
    "    ]\n",
    "    for b in blacklist:\n",
    "        s = re.sub(b, '', s)\n",
    "    return s.strip()\n",
    "single_word_drugs_list = list(pd.Series(single_word_drugs).map(process_blacklist))\n",
    "single_word_drugs_list\n",
    "\n",
    "\n",
    "## L1000 API Integration\n",
    "L1000FWD_URL = 'http://amp.pharm.mssm.edu/L1000FWD/'\n",
    "\n",
    "\n",
    "L1000_reverse_drugs_store = []\n",
    "\n",
    "\n",
    "for a in single_word_drugs_list:\n",
    "    query_string = a\n",
    "    L1000_reverse_drug_response = requests.get(L1000FWD_URL + 'synonyms/' + query_string)\n",
    "    if L1000_reverse_drug_response.status_code == 200:\n",
    "        #pprint(L1000_reverse_drug_response.json())\n",
    "        L1000_reverse_significant_query = L1000_reverse_drug_response.json()\n",
    "        if len(L1000_reverse_significant_query) > 0:\n",
    "            json.dump(L1000_reverse_drug_response.json(), open(query_string + '_L1000_reverse_drug_query.json', 'w'), indent=4)\n",
    "            L1000_reverse_significant_query = L1000_reverse_drug_response.json()\n",
    "            L1000_reverse_significant_query_df = pd.DataFrame(L1000_reverse_significant_query)\n",
    "            L1000_reverse_drugs_store.append(a)\n",
    "            print(\"Found significant L1000 drug signatures for \" + query_string)\n",
    "        else:\n",
    "            print(\"No significant L1000 drug signatures for \" + query_string)\n",
    "  \n",
    "    \n",
    "    \n",
    "############################################################################################################################################\n",
    "##################################################################################################\n",
    "## X2K API integration \n",
    "\n",
    "# Import modules\n",
    "import http.client\n",
    "import json\n",
    "\n",
    "##### Function to run X2K\n",
    "### Input: a Python list of gene symbols\n",
    "### Output: a dictionary containing the results of X2K, ChEA, G2N, KEA.\n",
    "\n",
    "\n",
    "def run_X2K(input_genes, options={}):\n",
    "    # Open HTTP connection\n",
    "    conn = http.client.HTTPConnection(\"amp.pharm.mssm.edu\")\n",
    "\n",
    "    # Set default options\n",
    "    default_options = {'text-genes': '\\n'.join(input_genes),\n",
    "                       'included_organisms': 'both',\n",
    "                       'TF-target gene background database used for enrichment': 'ChEA & ENCODE Consensus',\n",
    "                       'sort transcription factors by': 'p-value',\n",
    "                       'min_network_size': 10,\n",
    "                       'number of top TFs': 10,\n",
    "                       'path_length': 2,\n",
    "                       'min_number_of_articles_supporting_interaction': 0,\n",
    "                       'max_number_of_interactions_per_protein': 200,\n",
    "                       'max_number_of_interactions_per_article': 100,\n",
    "                       'enable_BioGRID': True,\n",
    "                       'enable_IntAct': True,\n",
    "                       'enable_MINT': True,\n",
    "                       'enable_ppid': True,\n",
    "                       'enable_Stelzl': True,\n",
    "                       'kinase interactions to include': 'kea 2018',\n",
    "                       'sort kinases by': 'p-value'}\n",
    "\n",
    "    # Update options\n",
    "    for key, value in options.items():\n",
    "        if key in default_options.keys() and key != 'text-genes':\n",
    "            default_options.update({key: value})\n",
    "\n",
    "    # Get payload\n",
    "    boundary = \"----WebKitFormBoundary7MA4YWxkTrZu0gW\"\n",
    "    payload = ''.join(\n",
    "        ['--' + boundary + '\\r\\nContent-Disposition: form-data; name=\\\"{key}\\\"\\r\\n\\r\\n{value}\\r\\n'.format(**locals())\n",
    "         for key, value in default_options.items()]) + '--' + boundary + '--'\n",
    "\n",
    "    # Get Headers\n",
    "    headers = {\n",
    "        'content-type': \"multipart/form-data; boundary=\" + boundary,\n",
    "        'cache-control': \"no-cache\",\n",
    "    }\n",
    "\n",
    "    # Initialize connection\n",
    "    conn.request(\"POST\", \"/X2K/api\", payload, headers)\n",
    "\n",
    "    # Get response\n",
    "    res = conn.getresponse()\n",
    "\n",
    "    # Read response\n",
    "    data = res.read().decode('utf-8')\n",
    "\n",
    "    # Convert to dictionary\n",
    "    x2k_results = {key: json.loads(value) if key != 'input' else value for key, value in json.loads(data).items()}\n",
    "\n",
    "    # Clean results\n",
    "    x2k_results['ChEA'] = x2k_results['ChEA']['tfs']\n",
    "    x2k_results['G2N'] = x2k_results['G2N']['network']\n",
    "    x2k_results['KEA'] = x2k_results['KEA']['kinases']\n",
    "    x2k_results['X2K'] = x2k_results['X2K']['network']\n",
    "\n",
    "    # Return results\n",
    "    return x2k_results\n",
    "####################################################################################################################################\n",
    "### CREEDS DRUG CARD \n",
    "while(\"\" in single_word_drugs_list):\n",
    "    single_word_drugs_list.remove(\"\")\n",
    "    \n",
    "single_word_drugs_list = \"PREDNISONE\"\n",
    "CREEDS_URL = 'http://amp.pharm.mssm.edu/CREEDS/'\n",
    "\n",
    "CREEDS_drug_from_disease_up_genes = []\n",
    "CREEDS_drug_from_disease_down_genes = []\n",
    "\n",
    "for a in single_word_drugs_list:\n",
    "    CREEEDS_Drug_response = requests.get(CREEDS_URL + 'search', params={'q':str(a)})\n",
    "    if CREEEDS_Drug_response.status_code == 200:\n",
    "        #pprint(CREEEDS_Drug_response.json())\n",
    "        #json.dump(CREEEDS_Drug_response.json(), open(DrOI + '_api1_result.json', 'w'), indent=4)\n",
    "        CREEDS_drug_output_df = pd.DataFrame(CREEEDS_Drug_response.json())\n",
    "        \n",
    "        if len(CREEDS_drug_output_df) > 0:\n",
    "            CREEDS_drug_output_ids = list(CREEDS_drug_output_df[\"id\"])\n",
    "            print(\"CREEDS IDs found for \" + a)\n",
    "            for a in CREEDS_drug_output_ids:\n",
    "                CREEDS_drug_sigs_response = requests.get(CREEDS_URL + 'api', params={'id':'drug:DM609'})\n",
    "                if CREEDS_drug_sigs_response.status_code == 200:\n",
    "                    CREEDS_drug_sigs_response_json = CREEDS_drug_sigs_response.json()\n",
    "\n",
    "                    ## up genes\n",
    "                    CREEDS_drug_sigs_up_genes = CREEDS_drug_sigs_response_json['up_genes']\n",
    "                    CREEDS_drug_sigs_up_genes_df = pd.DataFrame(CREEDS_drug_sigs_up_genes) # this is the up genes dataframe\n",
    "                    CREEDS_drug_sigs_up_genes_df.columns= [\"Up_Genes\", \"Score\"]\n",
    "                    CREEDS_drug_sig_up_genes_list = list(CREEDS_drug_sigs_up_genes_df.Up_Genes)\n",
    "                    filename1 = (a + \"_CREEDS_drug_sig_up_genes.csv\")\n",
    "                    #CREEDS_drug_sigs_up_genes_df.to_csv(filename1) # this saves the df as a csv\n",
    "\n",
    "                    ## down genes\n",
    "                    CREEDS_drug_sigs_down_genes = CREEDS_drug_sigs_response_json['down_genes']\n",
    "                    CREEDS_drug_sigs_down_genes_df = pd.DataFrame(CREEDS_drug_sigs_down_genes)# this is the down genes dataframe\n",
    "                    filename2 = (a + \"_CREEDS_drug_sig_down_genes.csv\")\n",
    "                    CREEDS_drug_sigs_down_genes_df.columns= [\"Down_Genes\", \"Score\"]\n",
    "                    CREEDS_drug_sig_down_genes_list = list(CREEDS_drug_sigs_down_genes_df.Down_Genes)\n",
    "                    #print(filename2)\n",
    "                    #CREEDS_drug_sigs_down_genes_df.to_csv(filename2)\n",
    "                    #CREEDS_drug_sigs_down_genes = CREEDS_drug_sigs_response_json['down_genes'] # this saves the df as a csv\n",
    "\n",
    "                    ## json propagation\n",
    "                    #pprint(response.json())\n",
    "                    #json.dump(response.json(), open(a + '_CREEDS_Drug_sig.json', 'w'), indent=4) # if the user wants the entire json, they can download this\n",
    "\n",
    "                    CREEDS_drug_from_disease_up_genes.append(CREEDS_drug_sigs_up_genes)\n",
    "                    CREEDS_drug_from_disease_down_genes.append(CREEDS_drug_sigs_down_genes_df)\n",
    "                    \n",
    "                    \n",
    "                     \n",
    "                    ## X2K implementation\n",
    "\n",
    "                    ## up genes\n",
    "                    CREEDS_X2K_up_genes = run_X2K(CREEDS_drug_sig_up_genes_list)\n",
    "                    CREEDS_X2K_up_genes = CREEDS_X2K_up_genes[\"X2K\"]\n",
    "                    CREEDS_X2K_up_genes_df = pd.DataFrame(CREEDS_X2K_up_genes['nodes'])\n",
    "                    filename_up = (a + \"_CREEDS_X2K_up_genes.csv\")\n",
    "                    #CREEDS_X2K_up_genes_df.to_csv(filename_up) # THIS IS THE FILE THEY SHOULD BE ABLE TO DOWNLOAD\n",
    "\n",
    "                    ## down genes\n",
    "                    CREEDS_X2K_down_genes = run_X2K(CREEDS_drug_sig_down_genes_list)\n",
    "                    CREEDS_X2K_down_genes = CREEDS_X2K_down_genes[\"X2K\"]\n",
    "                    CREEDS_X2K_down_genes_df = pd.DataFrame(CREEDS_X2K_down_genes['nodes'])\n",
    "                    filename_down = (a + \"_CREEDS_X2K_down_genes.csv\")\n",
    "                    CREEDS_X2K_down_genes_df.to_csv(filename_down) # THIS IS THE FILE THEY SHOULD BE ABLE TO DOWNLOAD\n",
    "                    \n",
    "                  \n",
    "        else:\n",
    "            print (\"No CREEDS IDs found for \" + a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Fgf2\n",
       "1                     Smad5\n",
       "2                      Ibsp\n",
       "3                     Penk1\n",
       "4                     Sert1\n",
       "5                      Fth1\n",
       "6          Pnpla2_predicted\n",
       "7                     Hmga2\n",
       "8                       Fos\n",
       "9                     Ccng1\n",
       "10                    Acadl\n",
       "11                     Cd36\n",
       "12                    Cpt1b\n",
       "13                     Araf\n",
       "14                      Ckm\n",
       "15     RGD1564596_predicted\n",
       "16                     Pklr\n",
       "17                    Sepp1\n",
       "18                   Atp5g2\n",
       "19                     Bag3\n",
       "20                    Cox5a\n",
       "21                    Nisch\n",
       "22                     Rpl6\n",
       "23                   Ndufa5\n",
       "24                      Dsp\n",
       "25     RGD1305801_predicted\n",
       "26         Sorbs1_predicted\n",
       "27     RGD1565641_predicted\n",
       "28                   Atp5c1\n",
       "29                    Prph1\n",
       "               ...         \n",
       "278        Ankmy2_predicted\n",
       "279    RGD1561878_predicted\n",
       "280                    Stx7\n",
       "281                    Bzw2\n",
       "282                   Mosc2\n",
       "283                   Gstp2\n",
       "284                    Lias\n",
       "285                   Chpt1\n",
       "286                    Brd2\n",
       "287         Plac8_predicted\n",
       "288        Cggbp1_predicted\n",
       "289                Serping1\n",
       "290                  TSEN34\n",
       "291          Fech_predicted\n",
       "292                    Wars\n",
       "293                    Dkk3\n",
       "294                   Nr1h2\n",
       "295         Uhrf2_predicted\n",
       "296    RGD1311499_predicted\n",
       "297                  Igfbp6\n",
       "298                  Ppap2b\n",
       "299                 Pacsin3\n",
       "300                Nipsnap1\n",
       "301                     G10\n",
       "302                   Dnpep\n",
       "303           Me3_predicted\n",
       "304                 Tm4sf12\n",
       "305               LOC365960\n",
       "306                  Ndfip1\n",
       "307    RGD1560938_predicted\n",
       "Name: Up_Genes, Length: 308, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CREEDS_drug_sigs_up_genes_df.columns= [\"Up_Genes\", \"Score\"]\n",
    "CREEDS_drug_sigs_up_genes_df.Up_Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
